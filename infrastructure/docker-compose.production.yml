# TailTracker Production Infrastructure
# Docker Compose for production deployment with monitoring and scaling
#
# Version: 1.2.0
# Updated: 2025-12-29
# - Pinned all image versions for reproducibility
# - nginx: 1.28.1-alpine (stable)
# - redis: 7.4-alpine
# - elasticsearch/logstash/kibana: 8.17.0
# - prometheus: v3.1.0 / grafana: 11.4.0
# - jaeger: 1.64 / node-exporter: v1.8.2 / alertmanager: v0.28.0

networks:
  tailtracker_network:
    driver: bridge
  monitoring:
    driver: bridge

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  elasticsearch_data:
    driver: local

services:
  # Reverse Proxy & Load Balancer
  nginx:
    image: nginx:1.28.1-alpine
    container_name: tailtracker_nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ./nginx/logs:/var/log/nginx
    networks:
      - tailtracker_network
    depends_on:
      - api_server_1
      - api_server_2
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # API Server Instances (Load Balanced)
  api_server_1:
    image: tailtracker/api:latest
    container_name: tailtracker_api_1
    environment:
      - NODE_ENV=production
      - PORT=3000
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_CACHE_URL=${REDIS_CACHE_URL}
      - REDIS_SESSIONS_URL=${REDIS_SESSIONS_URL}
      - REDIS_PUBSUB_URL=${REDIS_PUBSUB_URL}
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_ANON_KEY=${SUPABASE_ANON_KEY}
      - SUPABASE_SERVICE_ROLE_KEY=${SUPABASE_SERVICE_ROLE_KEY}
      - JWT_SECRET=${JWT_SECRET}
      - ENCRYPTION_KEY=${ENCRYPTION_KEY}
      - STRIPE_SECRET_KEY=${STRIPE_SECRET_KEY}
      - REVENUECAT_API_KEY=${REVENUECAT_API_KEY}
    volumes:
      - ./logs:/app/logs
    networks:
      - tailtracker_network
      - monitoring
    depends_on:
      - redis_cache
      - redis_sessions
      - redis_pubsub
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  api_server_2:
    image: tailtracker/api:latest
    container_name: tailtracker_api_2
    environment:
      - NODE_ENV=production
      - PORT=3000
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_CACHE_URL=${REDIS_CACHE_URL}
      - REDIS_SESSIONS_URL=${REDIS_SESSIONS_URL}
      - REDIS_PUBSUB_URL=${REDIS_PUBSUB_URL}
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_ANON_KEY=${SUPABASE_ANON_KEY}
      - SUPABASE_SERVICE_ROLE_KEY=${SUPABASE_SERVICE_ROLE_KEY}
      - JWT_SECRET=${JWT_SECRET}
      - ENCRYPTION_KEY=${ENCRYPTION_KEY}
      - STRIPE_SECRET_KEY=${STRIPE_SECRET_KEY}
      - REVENUECAT_API_KEY=${REVENUECAT_API_KEY}
    volumes:
      - ./logs:/app/logs
    networks:
      - tailtracker_network
      - monitoring
    depends_on:
      - redis_cache
      - redis_sessions
      - redis_pubsub
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  # Redis Instances (Separated by Use Case)
  redis_cache:
    image: redis:7.4-alpine
    container_name: tailtracker_redis_cache
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
      - ./redis/redis-cache.conf:/usr/local/etc/redis/redis.conf
    networks:
      - tailtracker_network
      - monitoring
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  redis_sessions:
    image: redis:7.4-alpine
    container_name: tailtracker_redis_sessions
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy volatile-ttl
    ports:
      - "6380:6379"
    volumes:
      - ./redis/redis-sessions.conf:/usr/local/etc/redis/redis.conf
    networks:
      - tailtracker_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  redis_pubsub:
    image: redis:7.4-alpine
    container_name: tailtracker_redis_pubsub
    command: redis-server --maxmemory 128mb
    ports:
      - "6381:6379"
    networks:
      - tailtracker_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Background Job Processor
  job_processor:
    image: tailtracker/api:latest
    container_name: tailtracker_jobs
    command: ["node", "workers/job_processor.js"]
    environment:
      - NODE_ENV=production
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_CACHE_URL=${REDIS_CACHE_URL}
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_SERVICE_ROLE_KEY=${SUPABASE_SERVICE_ROLE_KEY}
      - SMTP_HOST=${SMTP_HOST}
      - SMTP_PORT=${SMTP_PORT}
      - SMTP_USER=${SMTP_USER}
      - SMTP_PASS=${SMTP_PASS}
    networks:
      - tailtracker_network
      - monitoring
    depends_on:
      - redis_cache
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  # Monitoring Stack
  prometheus:
    image: prom/prometheus:v3.1.0
    container_name: tailtracker_prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./monitoring/alerts.yml:/etc/prometheus/alerts.yml
      - prometheus_data:/prometheus
    networks:
      - monitoring
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    restart: unless-stopped

  grafana:
    image: grafana/grafana:11.4.0
    container_name: tailtracker_grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}
      - GF_SMTP_ENABLED=true
      - GF_SMTP_HOST=${SMTP_HOST}:${SMTP_PORT}
      - GF_SMTP_USER=${SMTP_USER}
      - GF_SMTP_PASSWORD=${SMTP_PASS}
      - GF_SMTP_FROM_ADDRESS=alerts@tailtracker.com
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    networks:
      - monitoring
    depends_on:
      - prometheus
    restart: unless-stopped

  # Log Management
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.17.0
    container_name: tailtracker_elasticsearch
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    networks:
      - monitoring
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G

  logstash:
    image: docker.elastic.co/logstash/logstash:8.17.0
    container_name: tailtracker_logstash
    ports:
      - "5044:5044"
      - "5000:5000/tcp"
      - "5000:5000/udp"
      - "9600:9600"
    environment:
      LS_JAVA_OPTS: "-Xmx256m -Xms256m"
    volumes:
      - ./monitoring/logstash/pipeline:/usr/share/logstash/pipeline
      - ./monitoring/logstash/logstash.yml:/usr/share/logstash/config/logstash.yml
      - ./logs:/usr/share/logstash/logs
    networks:
      - monitoring
    depends_on:
      - elasticsearch
    restart: unless-stopped

  kibana:
    image: docker.elastic.co/kibana/kibana:8.17.0
    container_name: tailtracker_kibana
    ports:
      - "5601:5601"
    environment:
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
    networks:
      - monitoring
    depends_on:
      - elasticsearch
    restart: unless-stopped

  # Application Performance Monitoring
  jaeger:
    image: jaegertracing/all-in-one:1.64
    container_name: tailtracker_jaeger
    ports:
      - "16686:16686"
      - "14268:14268"
    environment:
      - COLLECTOR_ZIPKIN_HOST_PORT=:9411
    networks:
      - monitoring
    restart: unless-stopped

  # Node Exporter for system metrics
  node_exporter:
    image: prom/node-exporter:v1.8.2
    container_name: tailtracker_node_exporter
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    networks:
      - monitoring
    restart: unless-stopped

  # Redis Exporter
  redis_exporter:
    image: oliver006/redis_exporter
    container_name: tailtracker_redis_exporter
    ports:
      - "9121:9121"
    environment:
      - REDIS_ADDR=redis://redis_cache:6379
    networks:
      - monitoring
    depends_on:
      - redis_cache
    restart: unless-stopped

  # Cadvisor for container metrics
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.51.0
    container_name: tailtracker_cadvisor
    ports:
      - "8080:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    networks:
      - monitoring
    restart: unless-stopped
    privileged: true

  # Alertmanager for alert routing
  alertmanager:
    image: prom/alertmanager:v0.28.0
    container_name: tailtracker_alertmanager
    ports:
      - "9093:9093"
    volumes:
      - ./monitoring/alertmanager.yml:/etc/alertmanager/alertmanager.yml
    networks:
      - monitoring
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
    restart: unless-stopped

  # Backup Service
  backup:
    image: tailtracker/backup:latest
    container_name: tailtracker_backup
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - S3_BACKUP_BUCKET=${S3_BACKUP_BUCKET}
      - BACKUP_SCHEDULE="0 2 * * *"  # Daily at 2 AM
    volumes:
      - ./backups:/backups
    networks:
      - tailtracker_network
    restart: unless-stopped

  # Health Check Service
  healthcheck:
    image: tailtracker/healthcheck:latest
    container_name: tailtracker_healthcheck
    environment:
      - API_ENDPOINTS=http://api_server_1:3000/health,http://api_server_2:3000/health
      - REDIS_ENDPOINTS=redis_cache:6379,redis_sessions:6379,redis_pubsub:6379
      - CHECK_INTERVAL=30
    networks:
      - tailtracker_network
      - monitoring
    depends_on:
      - api_server_1
      - api_server_2
      - redis_cache
    restart: unless-stopped